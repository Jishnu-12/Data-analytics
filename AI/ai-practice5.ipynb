{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ced8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"I had the most incredible dining experience at this restaurant! The food was absolutely delicious - every dish was perfectly \n",
    "prepared and beautifully presented. Our server was attentive, knowledgeable, and made excellent recommendations. \n",
    "The atmosphere was elegant yet comfortable. I can't wait to come back and try more items from their menu. Definitely a new favorite spot!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638fa116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'had', 'the', 'most', 'incredible', 'dining', 'experience', 'at', 'this', 'restaurant'], ['the', 'food', 'was', 'absolutely', 'delicious', 'every', 'dish', 'was', 'perfectly', 'prepared', 'and', 'beautifully', 'presented'], ['our', 'server', 'was', 'attentive', 'knowledgeable', 'and', 'made', 'excellent', 'recommendations'], ['the', 'atmosphere', 'was', 'elegant', 'yet', 'comfortable'], ['i', 'ca', \"n't\", 'wait', 'to', 'come', 'back', 'and', 'try', 'more', 'items', 'from', 'their', 'menu'], ['definitely', 'a', 'new', 'favorite', 'spot']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "import string\n",
    "\n",
    "token = sent_tokenize(review)\n",
    "\n",
    "all_word = []\n",
    "\n",
    "for i in token:\n",
    "    word = word_tokenize(i)\n",
    "    word = [w.lower() for w in word]\n",
    "    word = [ w for w in word if w not in string.punctuation]\n",
    "    all_word.append(word)\n",
    "\n",
    "print(all_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d0f818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['incredible', 'dining', 'experience', 'restaurant'],\n",
       " ['food',\n",
       "  'absolutely',\n",
       "  'delicious',\n",
       "  'every',\n",
       "  'dish',\n",
       "  'perfectly',\n",
       "  'prepared',\n",
       "  'beautifully',\n",
       "  'presented'],\n",
       " ['server',\n",
       "  'attentive',\n",
       "  'knowledgeable',\n",
       "  'made',\n",
       "  'excellent',\n",
       "  'recommendations'],\n",
       " ['atmosphere', 'elegant', 'yet', 'comfortable'],\n",
       " ['ca', \"n't\", 'wait', 'come', 'back', 'try', 'items', 'menu'],\n",
       " ['definitely', 'new', 'favorite', 'spot']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "clean = [\n",
    "    [w for w in sen if w not in stopword]\n",
    "    for sen in all_word\n",
    "]\n",
    "\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9dd0712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['incredible', 'dining', 'experience', 'restaurant'], ['food', 'absolutely', 'delicious', 'every', 'dish', 'perfectly', 'prepared', 'beautifully', 'presented'], ['server', 'attentive', 'knowledgeable', 'made', 'excellent', 'recommendation'], ['atmosphere', 'elegant', 'yet', 'comfortable'], ['ca', \"n't\", 'wait', 'come', 'back', 'try', 'item', 'menu'], ['definitely', 'new', 'favorite', 'spot']]\n",
      "[['incred', 'dine', 'experi', 'restaur'], ['food', 'absolut', 'delici', 'everi', 'dish', 'perfectli', 'prepar', 'beauti', 'present'], ['server', 'attent', 'knowledg', 'made', 'excel', 'recommend'], ['atmospher', 'eleg', 'yet', 'comfort'], ['ca', \"n't\", 'wait', 'come', 'back', 'tri', 'item', 'menu'], ['definit', 'new', 'favorit', 'spot']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lematized = [\n",
    "    [lemmatizer.lemmatize(w) for w in sentence]\n",
    "    for sentence in clean\n",
    "]\n",
    "\n",
    "stemmed = [\n",
    "    [stemmer.stem(w) for w in sen]\n",
    "    for sen in clean\n",
    "]\n",
    "\n",
    "print(lematized)\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec879d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "vectrorizer = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "document1 = [' '.join(w) for w in lematized]\n",
    "document2 = [' '.join(w) for w in stemmed]\n",
    "\n",
    "bow = vectrorizer.fit_transform(document1)\n",
    "matrix = tfidf.fit_transform(document2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d34e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely' 'atmosphere' 'attentive' 'back' 'beautifully' 'ca' 'come'\n",
      " 'comfortable' 'definitely' 'delicious' 'dining' 'dish' 'elegant' 'every'\n",
      " 'excellent' 'experience' 'favorite' 'food' 'incredible' 'item'\n",
      " 'knowledgeable' 'made' 'menu' 'new' 'perfectly' 'prepared' 'presented'\n",
      " 'recommendation' 'restaurant' 'server' 'spot' 'try' 'wait' 'yet']\n",
      "[[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vectrorizer.get_feature_names_out())\n",
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf948e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolut' 'atmospher' 'attent' 'back' 'beauti' 'ca' 'come' 'comfort'\n",
      " 'definit' 'delici' 'dine' 'dish' 'eleg' 'everi' 'excel' 'experi'\n",
      " 'favorit' 'food' 'incred' 'item' 'knowledg' 'made' 'menu' 'new'\n",
      " 'perfectli' 'prepar' 'present' 'recommend' 'restaur' 'server' 'spot'\n",
      " 'tri' 'wait' 'yet']\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.5        0.         0.\n",
      "  0.5        0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.33333333 0.         0.         0.         0.33333333 0.\n",
      "  0.         0.         0.         0.33333333 0.         0.33333333\n",
      "  0.         0.33333333 0.         0.         0.         0.33333333\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.33333333 0.33333333 0.33333333 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.40824829 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.40824829 0.         0.         0.\n",
      "  0.         0.         0.40824829 0.40824829 0.         0.\n",
      "  0.         0.         0.         0.40824829 0.         0.40824829\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.5        0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.         0.         0.\n",
      "  0.5        0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.5       ]\n",
      " [0.         0.         0.         0.37796447 0.         0.37796447\n",
      "  0.37796447 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.37796447 0.         0.         0.37796447 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.37796447 0.37796447 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.         0.         0.5\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.5        0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.get_feature_names_out())\n",
    "print(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015663f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
