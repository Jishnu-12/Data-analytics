{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6e0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"An associated ClaimReview, related by specific common content, topic or claim. The expectation is that this property would be most typically used in cases where a single activity is conducting both claim reviews and media reviews, in which case relatedMediaReview would commonly be used on a ClaimReview, while relatedClaimReview would be used on MediaReview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cee664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an associated claimreview, related by specific common content, topic or claim. the expectation is that this property would be most typically used in cases where a single activity is conducting both claim reviews and media reviews, in which case relatedmediareview would commonly be used on a claimreview, while relatedclaimreview would be used on mediareview'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.lower()\n",
    "\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0a0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an associated claimreview related by specific common content topic or claim the expectation is that this property would be most typically used in cases where a single activity is conducting both claim reviews and media reviews in which case relatedmediareview would commonly be used on a claimreview while relatedclaimreview would be used on mediareview\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "review = review.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdfd9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'associated', 'claimreview', 'related', 'by', 'specific', 'common', 'content', 'topic', 'or', 'claim', 'the', 'expectation', 'is', 'that', 'this', 'property', 'would', 'be', 'most', 'typically', 'used', 'in', 'cases', 'where', 'a', 'single', 'activity', 'is', 'conducting', 'both', 'claim', 'reviews', 'and', 'media', 'reviews', 'in', 'which', 'case', 'relatedmediareview', 'would', 'commonly', 'be', 'used', 'on', 'a', 'claimreview', 'while', 'relatedclaimreview', 'would', 'be', 'used', 'on', 'mediareview']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "token = word_tokenize(review)\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcb978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['associated', 'claimreview', 'related', 'specific', 'common', 'content', 'topic', 'claim', 'expectation', 'property', 'would', 'typically', 'used', 'cases', 'single', 'activity', 'conducting', 'claim', 'reviews', 'media', 'reviews', 'case', 'relatedmediareview', 'would', 'commonly', 'used', 'claimreview', 'relatedclaimreview', 'would', 'used', 'mediareview']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "remove_stopword = set(stopwords.words('english'))\n",
    "\n",
    "clean = [w for w in token if w not in remove_stopword]\n",
    "\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b849b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['associ', 'claimreview', 'relat', 'specif', 'common', 'content', 'topic', 'claim', 'expect', 'properti', 'would', 'typic', 'use', 'case', 'singl', 'activ', 'conduct', 'claim', 'review', 'media', 'review', 'case', 'relatedmediareview', 'would', 'commonli', 'use', 'claimreview', 'relatedclaimreview', 'would', 'use', 'mediareview']\n",
      "['associated', 'claimreview', 'related', 'specific', 'common', 'content', 'topic', 'claim', 'expectation', 'property', 'would', 'typically', 'used', 'case', 'single', 'activity', 'conducting', 'claim', 'review', 'medium', 'review', 'case', 'relatedmediareview', 'would', 'commonly', 'used', 'claimreview', 'relatedclaimreview', 'would', 'used', 'mediareview']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "text1 = [stemmer.stem(w) for w in clean]\n",
    "\n",
    "text2 = [lemmatizer.lemmatize(w) for w in clean]\n",
    "\n",
    "print(text1)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fecd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac3533da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activ' 'associ' 'case' 'claim' 'claimreview' 'common' 'commonli'\n",
      " 'conduct' 'content' 'expect' 'media' 'mediareview' 'properti' 'relat'\n",
      " 'relatedclaimreview' 'relatedmediareview' 'review' 'singl' 'specif'\n",
      " 'topic' 'typic' 'use' 'would']\n",
      "[[1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 3 3]]\n"
     ]
    }
   ],
   "source": [
    "text1_join = ' '.join(text1)\n",
    "\n",
    "bow = vectorizer.fit_transform([text1_join])\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bc326bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activity' 'associated' 'case' 'claim' 'claimreview' 'common' 'commonly'\n",
      " 'conducting' 'content' 'expectation' 'mediareview' 'medium' 'property'\n",
      " 'related' 'relatedclaimreview' 'relatedmediareview' 'review' 'single'\n",
      " 'specific' 'topic' 'typically' 'used' 'would']\n",
      "[[0.14002801 0.14002801 0.28005602 0.28005602 0.28005602 0.14002801\n",
      "  0.14002801 0.14002801 0.14002801 0.14002801 0.14002801 0.14002801\n",
      "  0.14002801 0.14002801 0.14002801 0.14002801 0.28005602 0.14002801\n",
      "  0.14002801 0.14002801 0.14002801 0.42008403 0.42008403]]\n"
     ]
    }
   ],
   "source": [
    "text2_join = ' '.join(text2)\n",
    "\n",
    "matrix = tfidf.fit_transform([text2_join])\n",
    "\n",
    "print(tfidf.get_feature_names_out())\n",
    "print(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc85f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
